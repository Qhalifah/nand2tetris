from Constants import *
from JackTokenizer import *
import unittest

class JackTokenizerTest(unittest.TestCase):
    def test_is_identifier(self):
        tokenizer = JackTokenizer("test.jack")
        self.assertFalse(tokenizer.is_identifier('123abc'))
        self.assertFalse(tokenizer.is_identifier('abc 123'))
        self.assertTrue(tokenizer.is_identifier('abc123'))
        self.assertTrue(tokenizer.is_identifier('_abc123'))

    def test_tokenizer(self):
        tokenizer = JackTokenizer("test.jack")
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'class')
        self.assertEqual(tokenizer.token_type(), KEYWORD)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'A')
        self.assertEqual(tokenizer.token_type(), IDENTIFIER)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '{')
        self.assertEqual(tokenizer.token_type(), SYMBOL)

        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'let')
        self.assertEqual(tokenizer.token_type(), KEYWORD)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'x')
        self.assertEqual(tokenizer.token_type(), IDENTIFIER)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '=')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '-')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '4')
        self.assertEqual(tokenizer.token_type(), INT_CONST)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, ';')
        self.assertEqual(tokenizer.token_type(), SYMBOL)

        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'do')
        self.assertEqual(tokenizer.token_type(), KEYWORD)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'Output')
        self.assertEqual(tokenizer.token_type(), IDENTIFIER)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '.')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, 'printString')
        self.assertEqual(tokenizer.token_type(), IDENTIFIER)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '(')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '"Huzzah!"')
        self.assertEqual(tokenizer.token_type(), STRING_CONST)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, ')')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, ';')
        self.assertEqual(tokenizer.token_type(), SYMBOL)

        tokenizer.has_more_tokens()
        tokenizer.advance()
        self.assertEqual(tokenizer.current_token, '}')
        self.assertEqual(tokenizer.token_type(), SYMBOL)
